API Documentation (v1)
=======================

Base URL: https://torbiz-backend.vercel.app/

---

## CLIENT ENDPOINTS

### POST /client/google-auth/
- Authorizations: Basic
- Response: 201

### GET /client/list/
- Authorizations: Basic
- Response: 200 (JSON Array of User Objects)

### POST /client/list/
- Request Body:
  - user: object
  - phone_no: string
  - user_image: integer
  - terms_accepted: boolean
- Response: 201 (User Object)

### GET /client/list/{id}/
- Response: 200 (User Object)

### PUT /client/list/{id}/
- Updates a client entry.
- Response: 200 (Updated User Object)

### PATCH /client/list/{id}/
- Partial update.
- Response: 200

### DELETE /client/list/{id}/
- Response: 204 (No Content)

---

## GPU ENDPOINTS

### GET /gpu/list/
- Response: 200 (Array of GPU Info)

### POST /gpu/list/
- Request Body: Hardware info (GPU, CPU, RAM, OS, etc.)
- Response: 201 (Created GPU Info)

### GET /gpu/list/{id}/
- Response: 200

### PUT /gpu/list/{id}/
- Full update.
- Response: 200

### PATCH /gpu/list/{id}/
- Partial update.
- Response: 200

### DELETE /gpu/list/{id}/
- Response: 204

---

## INFERENCE ENDPOINTS

### GET /inference/
- Lists all inference requests.

### POST /inference/
- Creates a new inference record.

### POST /inference/stream/
- Creates streaming inference record.

### GET /inference/{id}/
- Retrieves one inference record.

### PUT /inference/{id}/
- Updates inference record.

### PATCH /inference/{id}/
- Partial update.

### DELETE /inference/{id}/
- Deletes inference record.

---

## LLM MODELS ENDPOINTS

### GET /llm_models/all-models/
- Lists all models.

### POST /llm_models/register/
- Registers a GPU node.

### POST /llm_models/heartbeat/
- Node heartbeat ping.

### DELETE /llm_models/deregister/
- Deregisters GPU node.
