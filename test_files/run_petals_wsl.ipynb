{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a511ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139cdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# Default model to host. Llama 2 requires manual 'huggingface-cli login' inside WSL first.\n",
    "# Using a non-gated model is recommended for first-time automated setup.\n",
    "DEFAULT_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\" \n",
    "# --- End Configuration ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6afbf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_admin():\n",
    "    \"\"\"Checks if the script is running with Administrator privileges on Windows.\"\"\"\n",
    "    try:\n",
    "        return ctypes.windll.shell32.IsUserAnAdmin() == 1\n",
    "    except AttributeError:\n",
    "        return False  # Not on Windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6493cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_wsl_installed():\n",
    "    \"\"\"Checks if WSL is installed by running 'wsl.exe --list'.\"\"\"\n",
    "    print(\"Checking for WSL installation...\")\n",
    "    try:\n",
    "        # Use '--list' and check return code.\n",
    "        # '--quiet' is not used here to provide more context on failure.\n",
    "        subprocess.run(\n",
    "            ['wsl.exe', '--list', '--verbose'], \n",
    "            check=True, \n",
    "            capture_output=True, \n",
    "            text=True\n",
    "        )\n",
    "        print(\"...WSL installation detected.\")\n",
    "        return True\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        print(\"...WSL not detected.\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40058860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def install_wsl():\n",
    "    \"\"\"Triggers the WSL installation command.\"\"\"\n",
    "    print(\"--- [STAGE 1] WSL Installation ---\")\n",
    "    print(\"Attempting to install WSL with Ubuntu distribution...\")\n",
    "    print(\"This will open a new console window for the installer.\")\n",
    "    try:\n",
    "        # Run the installation in a new console window\n",
    "        subprocess.run(\n",
    "            ['wsl.exe', '--install', '-d', 'Ubuntu'], \n",
    "            check=True,\n",
    "            # This flag helps show the installer progress in its own window\n",
    "            creationflags=subprocess.CREATE_NEW_CONSOLE \n",
    "        )\n",
    "        print(\"\\n--- ACTION REQUIRED ---\")\n",
    "        print(\"1. WSL installation has been initiated.\")\n",
    "        print(\"2. Please REBOOT your computer to complete the installation.\")\n",
    "        print(\"3. After rebooting, a terminal may open to set up your Linux username and password. Please complete this.\")\n",
    "        print(\"4. After setup is complete, re-run this *same script* (run_petals_wsl.py) as Administrator.\")\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\nError: WSL installation failed (Code: {e.returncode}).\")\n",
    "        print(\"Please ensure virtualization is enabled in your BIOS and try again.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nError: 'wsl.exe' command not found. Your Windows version may be too old.\")\n",
    "    \n",
    "    sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74642a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_petals_in_wsl(model_name):\n",
    "    \"\"\"Executes the full Petals server setup and launch chain inside WSL as root.\"\"\"\n",
    "    \n",
    "    print(\"--- [STAGE 2] Petals Server Setup & Launch (inside WSL) ---\")\n",
    "    \n",
    "    # Check for manual Hugging Face login requirement\n",
    "    if \"llama\" in model_name.lower() or \"mixtral\" in model_name.lower():\n",
    "        print(\"\\n[!] WARNING: You have selected a gated model.\")\n",
    "        print(\"This automated script CANNOT bypass the Hugging Face login.\")\n",
    "        print(\"If you have not done so, this script will fail when downloading the model.\")\n",
    "        print(\"\\n--- MANUAL ACTION RECOMMENDED (before proceeding) ---\")\n",
    "        print(\"1. Open 'cmd'.\")\n",
    "        print(\"2. Type 'wsl'.\")\n",
    "        print(\"3. Inside the Linux terminal, run: huggingface-cli login\")\n",
    "        print(\"4. Follow the prompts to log in.\")\n",
    "        print(\"5. Type 'exit' to close WSL and return here.\")\n",
    "        \n",
    "        while True:\n",
    "            confirm = input(\"Have you logged in to Hugging Face inside WSL? (yes/no): \").strip().lower()\n",
    "            if confirm == 'yes':\n",
    "                break\n",
    "            elif confirm == 'no':\n",
    "                print(\"Please complete the manual login step first.\")\n",
    "                sys.exit(1)\n",
    "\n",
    "    print(\"\\nBuilding setup command for WSL...\")\n",
    "    \n",
    "    # This entire block is executed as a single command by 'bash -c'\n",
    "    # It runs as root to avoid all 'sudo' password prompts.\n",
    "    # Note: Using '\\' to escape newlines in a Python f-string requires the newline\n",
    "    # itself, which is why this is structured as a multi-line string.\n",
    "    \n",
    "    command_string = f\"\"\"\n",
    "echo '--- [1/5] Updating apt packages (this may take a while)... ---' && \\\n",
    "apt-get update -y && \\\n",
    "apt-get upgrade -y && \\\n",
    "\\\n",
    "echo '--- [2/5] Installing Python 3, pip, and venv... ---' && \\\n",
    "apt-get install python3 python3-pip python3-venv -y && \\\n",
    "\\\n",
    "echo '--- [3/5] Creating Python virtual environment at /opt/petals-env... ---' && \\\n",
    "python3 -m venv /opt/petals-env && \\\n",
    "\\\n",
    "echo '--- [4.1/5] Installing Petals... ---' && \\\n",
    "/opt/petals-env/bin/pip install petals && \\\n",
    "\\\n",
    "echo '--- [4.2/5] Installing PyTorch (CPU version)... ---' && \\\n",
    "/opt/petals-env/bin/pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu && \\\n",
    "\\\n",
    "echo '--- [5/5] All dependencies installed. Launching Petals server... ---' && \\\n",
    "echo '--- To stop the server, press Ctrl+C in this window. ---' && \\\n",
    "/opt/petals-env/bin/python -m petals.cli.run_server {model_name}\n",
    "\"\"\"\n",
    "\n",
    "    print(\"Starting setup and server launch inside WSL.\")\n",
    "    print(\"This will take a significant amount of time.\")\n",
    "    print(\"The output from WSL will stream below:\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    \n",
    "    try:\n",
    "        # Execute the entire chain using 'wsl.exe -u root'\n",
    "        subprocess.run(\n",
    "            ['wsl.exe', '-u', 'root', '-e', 'bash', '-c', command_string],\n",
    "            check=True\n",
    "        )\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n--- ERROR ---\")\n",
    "        print(f\"WSL setup failed with return code {e.returncode}.\")\n",
    "        print(\"Please review the output above for errors.\")\n",
    "        print(\"Common issues:\")\n",
    "        print(\" - You did not log in to Hugging Face for a gated model.\")\n",
    "        print(\" - An 'apt' or 'pip' package failed to install (network issue?).\")\n",
    "        print(f\" - The model '{model_name}' does not exist or is not supported.\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n--- Server terminated by user (Ctrl+C) ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca683cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() != \"Windows\":\n",
    "    print(\"Error: This script is designed for Windows 11 with WSL.\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20356f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Torbiz Petals Seeder Setup Script ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not is_admin():\n",
    "    print(\"Error: This script requires Administrator privileges to manage WSL.\")\n",
    "    print(\"Please re-run this script as Administrator.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"--- Torbiz Petals Seeder Setup Script ---\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5cadeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for WSL installation...\n",
      "...WSL installation detected.\n",
      "--- [STAGE 2] Petals Server Setup & Launch (inside WSL) ---\n",
      "\n",
      "[!] WARNING: You have selected a gated model.\n",
      "This automated script CANNOT bypass the Hugging Face login.\n",
      "If you have not done so, this script will fail when downloading the model.\n",
      "\n",
      "--- MANUAL ACTION RECOMMENDED (before proceeding) ---\n",
      "1. Open 'cmd'.\n",
      "2. Type 'wsl'.\n",
      "3. Inside the Linux terminal, run: huggingface-cli login\n",
      "4. Follow the prompts to log in.\n",
      "5. Type 'exit' to close WSL and return here.\n",
      "\n",
      "Building setup command for WSL...\n",
      "Starting setup and server launch inside WSL.\n",
      "This will take a significant amount of time.\n",
      "The output from WSL will stream below:\n",
      "---------------------------------------------------------\n",
      "\n",
      "--- ERROR ---\n",
      "WSL setup failed with return code 1.\n",
      "Please review the output above for errors.\n",
      "Common issues:\n",
      " - You did not log in to Hugging Face for a gated model.\n",
      " - An 'apt' or 'pip' package failed to install (network issue?).\n",
      " - The model 'TinyLlama/TinyLlama-1.1B-Chat-v1.0' does not exist or is not supported.\n"
     ]
    }
   ],
   "source": [
    "if check_wsl_installed():\n",
    "    # STAGE 2: WSL is present, run the setup.\n",
    "    model = input(f\"Enter the Hugging Face model name to host [{DEFAULT_MODEL}]: \")\n",
    "    if not model:\n",
    "        model = DEFAULT_MODEL\n",
    "    \n",
    "    run_petals_in_wsl(model.strip())\n",
    "else:\n",
    "    # STAGE 1: WSL is not present, install it.\n",
    "    install_wsl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b393b60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
